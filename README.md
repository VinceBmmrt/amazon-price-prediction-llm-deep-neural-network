# ðŸ·ï¸ Amazon Price Predictor Fine Tuning LLM and Deep-Neural Network-Pipeline

## ðŸ“Š Model Performance Comparison

![Model Performance](graph/graph%20model%20performance%20comparator%20for%20pricer%20final.jpg)

## ðŸ“ˆ Fine-Tuning Training (Weights & Biases)

![WandB Training](graph/wandb%20finetuning%20training%20screenshot.png)

LLaMA 3.2 fine-tunÃ© sur le dataset complet ($39.85) bat GPT-5.1 ($44.74), Claude 4.5 Sonnet ($47.10) et tous les modÃ¨les frontier testÃ©s â€” sans accÃ¨s aux poids propriÃ©taires, uniquement grÃ¢ce Ã  la spÃ©cialisation sur les donnÃ©es Amazon.

> **English version below** / Version franÃ§aise ci-dessus

---

## ðŸ‡«ðŸ‡· Version FranÃ§aise

### Vue d'ensemble

> *Hybrid ML pipeline combining LLM-based structured summarization with deep neural network regression and LLaMA 3.2 fine-tuning for price prediction â€” outperforming frontier models on this specific task.*

Ce projet implÃ©mente un pipeline ML de bout en bout pour prÃ©dire le prix d'un produit Amazon Ã  partir de sa description textuelle. L'idÃ©e centrale : utiliser un LLM pour structurer et nettoyer la donnÃ©e brute, puis tester plusieurs approches en montant progressivement en puissance â€” jusqu'au fine-tuning de **LLaMA 3.2** sur **+820 000 fiches produits**, avec des rÃ©sultats qui **surpassent les meilleurs modÃ¨les de la planÃ¨te** sur cette tÃ¢che spÃ©cifique.

**Points forts du pipeline :**
- ðŸ§¹ **Data Cleaning** â€” nettoyage rigoureux sur **+820 000 produits** : filtrage des prix, suppression des SKU, part numbers et champs parasites
- ðŸ¤– **LLM Preprocessing** â€” transformation des descriptions brutes en rÃ©sumÃ©s structurÃ©s via Groq, en **batches de 1 000 items** asynchrones
- ðŸ§  **Deep Neural Network** â€” rÃ©seau ResNet-style de **10 couches**, **4 096 neurones** par couche, **+100 millions de paramÃ¨tres**
- ðŸ¦™ **Fine-tuning LLaMA 3.2** â€” rÃ©sultats supÃ©rieurs Ã  GPT-5.1 et Claude Opus sur cette tÃ¢che de pricing
- ðŸ“Š **Ã‰valuation statistique** â€” MAE, MSE, RÂ², courbes d'erreur avec intervalles de confiance Ã  95 %
- âš¡ **ScalabilitÃ©** â€” traitement multi-processus (ProcessPool), batch asynchrone JSONL, support CUDA/MPS/CPU

---

### ðŸ—ºï¸ Progression du projet

Ce projet explore une montÃ©e en puissance progressive de 6 approches :

| Ã‰tape | Approche | RÃ©sultats |
|-------|----------|-----------|
| 1ï¸âƒ£ **Data Curation** | Chargement et nettoyage de +820 000 produits Amazon | â€” |
| 2ï¸âƒ£ **Data Pre-processing** | RÃ©sumÃ©s LLM via Groq â€” batches de 1 000 items | â€” |
| 3ï¸âƒ£ **Baselines & ML classique** | Random Forest, XGBoost | RÃ©fÃ©rence |
| 4ï¸âƒ£ **Deep Neural Network** | DNN ResNet-style : 10 couches, 4 096 neurones | âœ… OK |
| 5ï¸âƒ£ **Fine-tuning Frontier** | Fine-tuning GPT sur +820 000 exemples | âš ï¸ Moyen |
| 6ï¸âƒ£ **Fine-tuning LLaMA 3.2** | Fine-tuning open-source sur dataset complet | ðŸ† SOTA |

> ðŸ† Le fine-tuning de **LLaMA 3.2** sur ce dataset spÃ©cifique surpasse **GPT-5, Claude Opus et les meilleurs modÃ¨les frontier** sur la tÃ¢che de prÃ©diction de prix Amazon.

---

### ðŸ“Š Dataset

Source : **McAuley-Lab/Amazon-Reviews-2023** (HuggingFace)

| Version | Taille | Usage |
|---------|--------|-------|
| ðŸª¶ Lite | ~22 000 produits | DÃ©veloppement & tests rapides |
| ðŸ”¥ Full | ~820 000 produits | EntraÃ®nement complet |

Le dataset est nettoyÃ©, enrichi par LLM, puis poussÃ© sur le **HuggingFace Hub** pour Ãªtre rÃ©utilisÃ© Ã  chaque Ã©tape du pipeline.

---

### âš™ï¸ Installation

```bash
git clone https://github.com/ton-utilisateur/amazon-price-prediction-llm-deep-neural-network.git
cd amazon-price-prediction-llm-deep-neural-network
pip install -r requirements.txt
```

**Variables d'environnement** â€” crÃ©e un fichier `.env` :

```env
GROQ_API_KEY=ta_clÃ©_groq_ici
```

---

### ðŸ“¦ DÃ©pendances principales

| Librairie | Usage |
|-----------|-------|
| `torch` | RÃ©seau de neurones (PyTorch) |
| `transformers` | Fine-tuning LLaMA 3.2 |
| `pydantic` | Validation du modÃ¨le de donnÃ©es |
| `datasets` | Chargement du dataset HuggingFace |
| `scikit-learn` | Vectorisation & mÃ©triques |
| `groq` / `litellm` | Appels LLM (rÃ©sumÃ©s) |
| `plotly` | Visualisations interactives |
| `tqdm` | Barres de progression |
| `python-dotenv` | Gestion des variables d'environnement |

---

### ðŸ—‚ï¸ Description des modules

#### `pricer/items.py` â€” ModÃ¨le de donnÃ©es
DÃ©finit la classe `Item` via **Pydantic**. Chaque item reprÃ©sente un produit Amazon avec ses champs : `title`, `category`, `price`, `full` (texte brut jusqu'Ã  **4 000 caractÃ¨res**), `summary` (rÃ©sumÃ© LLM), `prompt`, etc.

FonctionnalitÃ©s clÃ©s :
- `make_prompt()` â€” gÃ©nÃ¨re le prompt d'entraÃ®nement
- `test_prompt()` â€” retourne le prompt sans le prix (pour infÃ©rence)
- `push_to_hub()` / `from_hub()` â€” intÃ©gration HuggingFace Hub

#### `pricer/loaders.py` â€” Chargement du dataset
Charge le dataset **McAuley-Lab/Amazon-Reviews-2023** depuis HuggingFace (**+820 000 produits** dans la version complÃ¨te). Face Ã  cette volumÃ©trie, un simple chargement sÃ©quentiel serait prohibitif : le module utilise un `ProcessPoolExecutor` pour distribuer le travail sur tous les cÅ“urs CPU disponibles, en dÃ©coupant le dataset en **chunks de 1 000 Ã©lÃ©ments** traitÃ©s en parallÃ¨le.

#### `pricer/parser.py` â€” Nettoyage des donnÃ©es
CÅ“ur du data engineering. Filtre et nettoie chaque produit :
- Plage de prix acceptÃ©e : **$0.50 â†’ $999.49**
- Supprime les numÃ©ros de piÃ¨ces, SKU alphanumÃ©riques et champs parasites (Best Sellers Rank, numÃ©ros de modÃ¨le, etc.)
- Normalise les poids en livres (supporte : pounds, ounces, grams, milligrams, kilograms)
- Limite le texte Ã  **4 000 caractÃ¨res** max (3 000 par champ)
- Exige un minimum de **600 caractÃ¨res** de contenu â€” les fiches trop courtes sont exclues

> âš ï¸ Un mauvais nettoyage = un modÃ¨le qui apprend du bruit. Cette Ã©tape est critique.

#### `pricer/preprocessor.py` â€” RÃ©sumÃ© LLM (unitaire)
Contient la classe `Preprocessor` qui utilise **litellm** pour appeler le modÃ¨le `groq/openai/gpt-oss-20b` et transformer une description produit longue en rÃ©sumÃ© structurÃ© en **5 champs** :

```
Title / Category / Brand / Description / Details
```

Suit Ã©galement les **tokens consommÃ©s et le coÃ»t total** des appels API (`total_input_tokens`, `total_output_tokens`, `total_cost`) â€” indispensable pour monitorer les dÃ©penses Ã  grande Ã©chelle.

#### `pricer/batch.py` â€” RÃ©sumÃ© LLM (batch scalable)
Version scalable du preprocessor. Traite le dataset entier en **batches de 1 000 items** via des jobs asynchrones Groq :
1. GÃ©nÃ¨re des fichiers `.jsonl` par batch de **1 000 items**
2. Upload les fichiers sur Groq
3. Lance des jobs asynchrones (fenÃªtre de **24h**)
4. RÃ©cupÃ¨re et applique les rÃ©sultats
5. Sauvegarde l'Ã©tat en `.pkl` pour reprendre si interruption

> ðŸ’¡ Sur **820 000 items**, cela reprÃ©sente **820 batches** traitÃ©s de faÃ§on asynchrone â€” beaucoup plus Ã©conomique que de payer 820 000 appels API individuels, et sans risque de timeout.

#### `pricer/deepneuralnetwork.py` â€” ModÃ¨le DNN

Un **DNN (Deep Neural Network)** dÃ©signe un rÃ©seau de neurones comportant de nombreuses couches cachÃ©es â€” par opposition Ã  un rÃ©seau superficiel. Ici, l'architecture pousse la profondeur Ã  l'extrÃªme pour capturer des relations complexes entre les mots d'une description et le prix d'un produit :

| ParamÃ¨tre | Valeur |
|-----------|--------|
| Couches cachÃ©es | **10** |
| Neurones par couche | **4 096** |
| Features d'entrÃ©e | **5 000** (HashingVectorizer) |
| ParamÃ¨tres entraÃ®nables | **~100 millions+** |
| Blocs rÃ©siduels | **8** (skip connections ResNet-style) |
| Batch size | **64** |
| Optimiseur | AdamW (lr=0.001, weight_decay=0.01) |
| Scheduler | CosineAnnealingLR |

```
Input (5 000) â†’ Linear(4 096) â†’ [ResidualBlock x8] â†’ Linear(1) â†’ Prix prÃ©dit
```

Les **blocs rÃ©siduels** (skip connections inspirÃ©es de ResNet) sont la clÃ© pour entraÃ®ner un rÃ©seau aussi profond sans que le gradient ne disparaisse. Les prix sont **transformÃ©s en log-scale** puis standardisÃ©s avant l'entraÃ®nement, ce qui stabilise considÃ©rablement la convergence. Le device est dÃ©tectÃ© automatiquement au lancement : **CUDA > MPS (Apple Silicon) > CPU**.

#### `pricer/evaluator.py` â€” Ã‰valuation
Ã‰value n'importe quelle fonction de prÃ©diction sur un Ã©chantillon (par dÃ©faut **200 points**) en parallÃ¨le via `ThreadPoolExecutor` (**5 workers**) :
- **MÃ©triques** : MAE (erreur absolue moyenne en $), MSE, RÂ²
- **Scatter plot** : prix prÃ©dit vs prix rÃ©el, colorÃ© par prÃ©cision (ðŸŸ¢ erreur < $40 ou < 20%, ðŸŸ¡ < $80 ou < 40%, ðŸ”´ au-delÃ )
- **Courbe d'erreur** : erreur cumulÃ©e avec intervalle de confiance Ã  **95 %**

---

#### `frontier/` â€” Fine-tuning modÃ¨les frontier (GPT)

PremiÃ¨re tentative de fine-tuning sur un modÃ¨le propriÃ©taire. Les rÃ©sultats se sont rÃ©vÃ©lÃ©s **moyens** : malgrÃ© l'utilisation de **+820 000 exemples**, le modÃ¨le peinait Ã  capturer la complexitÃ© des prix Amazon, probablement en raison des contraintes inhÃ©rentes aux modÃ¨les fermÃ©s (accÃ¨s limitÃ© aux poids, coÃ»t Ã©levÃ©, customisation restreinte).

- `items.py` â€” version adaptÃ©e du modÃ¨le de donnÃ©es pour le format fine-tuning
- `evaluator.py` â€” Ã©valuation comparative des rÃ©sultats frontier
- `utils.py` â€” utilitaires d'entraÃ®nement et de gestion des donnÃ©es

---

#### `llama3.2/` â€” Fine-tuning LLaMA 3.2 ðŸ†

L'approche finale et la plus performante. En fine-tunant **LLaMA 3.2** (modÃ¨le open-source) sur le dataset complet de **+820 000 fiches produits Amazon**, les rÃ©sultats dÃ©passent ceux obtenus avec les modÃ¨les frontier propriÃ©taires â€” et surpassent **GPT-4o, Claude et les meilleurs modÃ¨les disponibles** sur cette tÃ¢che spÃ©cifique de prÃ©diction de prix.

Pourquoi LLaMA 3.2 surpasse les modÃ¨les frontier ici :
- **SpÃ©cialisation totale** â€” accÃ¨s complet aux poids pour un fine-tuning profond
- **Volume de donnÃ©es** â€” +820 000 exemples domaine-spÃ©cifique vs connaissance gÃ©nÃ©raliste
- **Format adaptÃ©** â€” format `prompt/completion` optimisÃ© pour la tÃ¢che

`items.py` â€” version Ã©tendue avec support tokenizer, gestion de la longueur de sÃ©quence et format `prompt/completion` :
- `make_prompts()` â€” gÃ©nÃ¨re prompt + completion en tronquant intelligemment au max de tokens
- `count_tokens()` / `count_prompt_tokens()` â€” contrÃ´le prÃ©cis de la longueur des sÃ©quences
- `push_prompts_to_hub()` â€” pousse le dataset en format SFT (Supervised Fine-Tuning) sur HuggingFace

- `evaluator.py` â€” Ã©valuation avec parsing robuste des sorties LLM et intervalles de confiance Ã  95 %
- `utils.py` â€” utilitaires d'entraÃ®nement

---

### ðŸš€ Utilisation

```python
# 1. Charger les donnÃ©es (~820 000 produits)
from pricer.loaders import ItemLoader
items = ItemLoader("Electronics").load()

# 2. GÃ©nÃ©rer les rÃ©sumÃ©s en batch (820 batches de 1 000 items)
from pricer.batch import Batch
Batch.create(items, lite=False)
Batch.run()
Batch.fetch()

# 3. EntraÃ®ner le DNN (10 couches, 4 096 neurones, ~100M paramÃ¨tres)
from pricer.deepneuralnetwork import DeepNeuralNetworkRunner
runner = DeepNeuralNetworkRunner(train_items, val_items)
runner.setup()
runner.train(epochs=10)
runner.save("model.pt")

# 4. Fine-tuner LLaMA 3.2 (rÃ©sultats SOTA)
# Voir llama3.2/ pour les scripts d'entraÃ®nement

# 5. Ã‰valuer sur 200 points
from pricer.evaluator import evaluate
evaluate(runner.inference, test_items, size=200)
```

---

### ðŸ“Š MÃ©triques d'Ã©valuation

| MÃ©trique | Description |
|----------|-------------|
| **MAE** | Erreur absolue moyenne en dollars |
| **MSE** | Erreur quadratique moyenne |
| **RÂ²** | Coefficient de dÃ©termination (% variance expliquÃ©e) |

---

---

## ðŸ‡¬ðŸ‡§ English Version

### Overview

> *Hybrid ML pipeline combining LLM-based structured summarization with deep neural network regression and LLaMA 3.2 fine-tuning for price prediction â€” outperforming frontier models on this specific task.*

This project builds an end-to-end ML pipeline to predict an Amazon product's price from its text description. The core idea: use an LLM to structure and clean raw product data, then test progressively more powerful approaches â€” culminating in the fine-tuning of **LLaMA 3.2** on **820,000+ product listings**, with results that **outperform the best frontier models** on this specific task.

**Pipeline highlights:**
- ðŸ§¹ **Data Cleaning** â€” rigorous cleaning across **820,000+ products**: price filtering, SKU removal, part numbers and junk field stripping
- ðŸ¤– **LLM Preprocessing** â€” transforms raw descriptions into structured summaries via Groq, in async **batches of 1,000 items**
- ðŸ§  **Deep Neural Network** â€” ResNet-style network with **10 layers**, **4,096 neurons** per layer, **100M+ parameters**
- ðŸ¦™ **LLaMA 3.2 Fine-tuning** â€” results outperforming GPT-4o and Claude on this pricing task
- ðŸ“Š **Statistical Evaluation** â€” MAE, MSE, RÂ², error curves with 95% confidence intervals
- âš¡ **Scalability** â€” multi-process loading (ProcessPool), async JSONL batch jobs, CUDA/MPS/CPU auto-detection

---

### ðŸ—ºï¸ Project Progression

This project explores a progressive scale-up across 6 approaches:

| Step | Approach | Results |
|------|----------|---------|
| 1ï¸âƒ£ **Data Curation** | Loading and cleaning 820,000+ Amazon products | â€” |
| 2ï¸âƒ£ **Data Pre-processing** | LLM summaries via Groq â€” batches of 1,000 items | â€” |
| 3ï¸âƒ£ **Baselines & Classic ML** | Random Forest, XGBoost | Baseline |
| 4ï¸âƒ£ **Deep Neural Network** | ResNet-style DNN: 10 layers, 4,096 neurons | âœ… OK |
| 5ï¸âƒ£ **Frontier Fine-tuning** | GPT fine-tuning on 820,000+ examples | âš ï¸ Average |
| 6ï¸âƒ£ **LLaMA 3.2 Fine-tuning** | Open-source fine-tuning on full dataset | ðŸ† SOTA |

> ðŸ† Fine-tuning **LLaMA 3.2** on this domain-specific dataset outperforms **GPT-5.1, Claude Sonnet 4.5 and the best available frontier models** on the Amazon price prediction task.

---

### ðŸ“Š Dataset

Source: **McAuley-Lab/Amazon-Reviews-2023** (HuggingFace)

| Version | Size | Usage |
|---------|------|-------|
| ðŸª¶ Lite | ~22,000 products | Development & fast iteration |
| ðŸ”¥ Full | ~820,000 products | Full training |

The dataset is cleaned, LLM-enriched, then pushed to the **HuggingFace Hub** and reused at each stage of the pipeline.

---

### ðŸ—ƒï¸ Project Structure

```
amazon-price-prediction-llm-deep-neural-network/
â”œâ”€â”€ pricer/                        â†’ Core pipeline (data + DNN)
â”‚   â”œâ”€â”€ items.py                   â†’ Pydantic data model
â”‚   â”œâ”€â”€ parser.py                  â†’ Raw data cleaning and filtering
â”‚   â”œâ”€â”€ loaders.py                 â†’ Parallel loading of 820,000+ products
â”‚   â”œâ”€â”€ preprocessor.py            â†’ LLM summarization (single call)
â”‚   â”œâ”€â”€ batch.py                   â†’ Bulk LLM summarization (1,000 items/batch)
â”‚   â”œâ”€â”€ deepneuralnetwork.py       â†’ DNN: 10 layers, 4,096 neurons, residual blocks
â”‚   â””â”€â”€ evaluator.py               â†’ MAE/MSE/RÂ² evaluation with visualizations
â”‚
â”œâ”€â”€ frontier/                      â†’ Frontier model fine-tuning (GPT)
â”‚   â”œâ”€â”€ items.py                   â†’ Data model adapted for fine-tuning format
â”‚   â”œâ”€â”€ evaluator.py               â†’ Frontier model evaluation
â”‚   â””â”€â”€ utils.py                   â†’ Utilities
â”‚
â””â”€â”€ llama3.2/                      â†’ LLaMA 3.2 fine-tuning ðŸ†
    â”œâ”€â”€ items.py                   â†’ Extended model (prompt/completion + tokenizer)
    â”œâ”€â”€ evaluator.py               â†’ Evaluation with 95% confidence intervals
    â””â”€â”€ utils.py                   â†’ Training utilities
```

---

### âš™ï¸ Installation

```bash
git clone https://github.com/your-username/amazon-price-prediction-llm-deep-neural-network.git
cd amazon-price-prediction-llm-deep-neural-network
pip install -r requirements.txt
```

**Environment variables** â€” create a `.env` file:

```env
GROQ_API_KEY=your_groq_api_key_here
```

---

### ðŸ“¦ Main Dependencies

| Library | Usage |
|---------|-------|
| `torch` | Neural network (PyTorch) |
| `transformers` | LLaMA 3.2 fine-tuning |
| `pydantic` | Data model validation |
| `datasets` | HuggingFace dataset loading |
| `scikit-learn` | Vectorization & metrics |
| `groq` / `litellm` | LLM API calls (summaries) |
| `plotly` | Interactive visualizations |
| `tqdm` | Progress bars |
| `python-dotenv` | Environment variable management |

---

### ðŸ—‚ï¸ Module Descriptions

#### `pricer/items.py` â€” Data Model
Defines the `Item` class using **Pydantic**. Each item represents an Amazon product with fields: `title`, `category`, `price`, `full` (raw text up to **4,000 characters**), `summary` (LLM summary), `prompt`, etc.

Key methods:
- `make_prompt()` â€” generates the training prompt
- `test_prompt()` â€” returns the prompt without the price (for inference)
- `push_to_hub()` / `from_hub()` â€” HuggingFace Hub integration

#### `pricer/loaders.py` â€” Dataset Loading
Loads the **McAuley-Lab/Amazon-Reviews-2023** dataset from HuggingFace (**820,000+ products** in full mode). At this scale, sequential loading would be prohibitive: the module uses a `ProcessPoolExecutor` to distribute work across all available CPU cores, splitting the dataset into **chunks of 1,000 items** processed in parallel.

#### `pricer/parser.py` â€” Data Cleaning
The data engineering core. Filters and cleans each product:
- Accepted price range: **$0.50 â†’ $999.49**
- Removes part numbers, alphanumeric SKUs and noisy fields (Best Sellers Rank, model numbers, etc.)
- Normalizes weights to pounds (supports: pounds, ounces, grams, milligrams, kilograms)
- Caps text at **4,000 characters** max (3,000 per field)
- Requires a minimum of **600 characters** of content â€” short listings are excluded

> âš ï¸ Poor cleaning means the model learns noise instead of signal. This step is critical.

#### `pricer/preprocessor.py` â€” LLM Summarization (single call)
Contains the `Preprocessor` class that uses **litellm** to call the `groq/openai/gpt-oss-20b` model and transform a long product description into a structured **5-field summary**:

```
Title / Category / Brand / Description / Details
```

Also tracks **token usage and total API cost** (`total_input_tokens`, `total_output_tokens`, `total_cost`) â€” essential for monitoring spending at scale.

#### `pricer/batch.py` â€” LLM Summarization (scalable batch)
Scalable version of the preprocessor. Processes the entire dataset in **batches of 1,000 items** via async Groq jobs:
1. Generates `.jsonl` files in batches of **1,000 items**
2. Uploads files to Groq
3. Launches async jobs (completion window: **24h**)
4. Fetches and applies results
5. Saves state as `.pkl` to resume after interruption

> ðŸ’¡ On **820,000 items**, this means **820 batches** processed asynchronously â€” far more cost-effective than paying for 820,000 individual API calls, and with no timeout risk.

#### `pricer/deepneuralnetwork.py` â€” DNN Model

A **DNN (Deep Neural Network)** is a neural network with many hidden layers â€” as opposed to shallow architectures. Here, the depth is pushed to the extreme to capture complex relationships between product description words and price:

| Parameter | Value |
|-----------|-------|
| Hidden layers | **10** |
| Neurons per layer | **4,096** |
| Input features | **5,000** (HashingVectorizer) |
| Trainable parameters | **~100M+** |
| Residual blocks | **8** (ResNet-style skip connections) |
| Batch size | **64** |
| Optimizer | AdamW (lr=0.001, weight_decay=0.01) |
| Scheduler | CosineAnnealingLR |

```
Input (5,000) â†’ Linear(4,096) â†’ [ResidualBlock x8] â†’ Linear(1) â†’ Predicted price
```

**Residual blocks** (ResNet-inspired skip connections) are the key to training a network this deep without gradients vanishing. Prices are **log-transformed** then standardized before training, which significantly stabilizes convergence. The device is auto-detected at startup: **CUDA > MPS (Apple Silicon) > CPU**.

#### `pricer/evaluator.py` â€” Evaluation
Evaluates any prediction function on a data sample (default **200 points**) in parallel via `ThreadPoolExecutor` (**5 workers**):
- **Metrics**: MAE (mean absolute error in $), MSE, RÂ²
- **Scatter plot**: predicted vs actual price, color-coded by accuracy (ðŸŸ¢ error < $40 or < 20%, ðŸŸ¡ < $80 or < 40%, ðŸ”´ beyond)
- **Error curve**: cumulative error with **95% confidence interval**

---

#### `frontier/` â€” Frontier Model Fine-tuning (GPT)

The first fine-tuning attempt, using a proprietary frontier model. Despite training on **820,000+ examples**, results were **average**: the model struggled to match the complexity of Amazon pricing, likely due to the inherent constraints of closed models (limited weight access, high cost, restricted customization).

- `items.py` â€” adapted data model for the fine-tuning format
- `evaluator.py` â€” comparative evaluation of frontier results
- `utils.py` â€” training and data utilities

---

#### `llama3.2/` â€” LLaMA 3.2 Fine-tuning ðŸ†

The final and most powerful approach. By fine-tuning **LLaMA 3.2** (open-source) on the full dataset of **820,000+ Amazon product listings**, the results exceed those of proprietary frontier models â€” outperforming **GPT-5.1, Claude Sonnet and the best available models** on this specific pricing task.

Why LLaMA 3.2 outperforms frontier models here:
- **Total specialization** â€” full weight access enables deep fine-tuning
- **Data volume** â€” 820,000+ domain-specific examples vs generalist knowledge
- **Optimized format** â€” `prompt/completion` format tailored to the task

`items.py` â€” extended version with tokenizer support, sequence length management and `prompt/completion` format:
- `make_prompts()` â€” generates prompt + completion with intelligent token truncation
- `count_tokens()` / `count_prompt_tokens()` â€” precise sequence length control
- `push_prompts_to_hub()` â€” pushes dataset in SFT (Supervised Fine-Tuning) format to HuggingFace

- `evaluator.py` â€” evaluation with robust LLM output parsing and 95% confidence intervals
- `utils.py` â€” training utilities

---

### ðŸš€ Usage

```python
# 1. Load data (~820,000 products)
from pricer.loaders import ItemLoader
items = ItemLoader("Electronics").load()

# 2. Generate summaries in batch (820 batches of 1,000 items)
from pricer.batch import Batch
Batch.create(items, lite=False)
Batch.run()
Batch.fetch()

# 3. Train the DNN (10 layers, 4,096 neurons, ~100M parameters)
from pricer.deepneuralnetwork import DeepNeuralNetworkRunner
runner = DeepNeuralNetworkRunner(train_items, val_items)
runner.setup()
runner.train(epochs=10)
runner.save("model.pt")

# 4. Fine-tune LLaMA 3.2 (SOTA results)
# See llama3.2/ for training scripts

# 5. Evaluate on 200 data points
from pricer.evaluator import evaluate
evaluate(runner.inference, test_items, size=200)
```

---

### ðŸ“Š Evaluation Metrics

| Metric | Description |
|--------|-------------|
| **MAE** | Mean Absolute Error in dollars |
| **MSE** | Mean Squared Error |
| **RÂ²** | Coefficient of determination (% variance explained) |

---

### ðŸ“„ License

MIT License â€” feel free to use, modify, and distribute.
